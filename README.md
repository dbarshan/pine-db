# PineDB
*A Modular Columnar SQL Database Engine*

---

## ðŸ“Œ 1. Objective

To design and implement a modular, columnar SQL-based database engine that starts with simple text-based storage and can be progressively extended to support advanced features like binary storage, indexing (B+ Trees), and optimized execution engines.

---

## ðŸ“Œ 2. Scope â€“ Phase 1 (MVP)

This phase focuses on:

* A **columnar storage engine** using flat text files.
* A **basic SQL parser** to handle standard SQL commands.
* A **modular architecture** allowing easy upgrade of storage and indexing.
* Support for simple **DDL** and **DML** operations.

---

## ðŸ“Œ 3. Functional Requirements

### 3.1 Storage Engine

* Store each column of a table in a **separate text file**.
* File format: CSV or line-separated raw values.
* Metadata (schema, table definition) stored in a JSON or meta file.
* Tables and columns should be discoverable via metadata.
* All data is persisted in a designated **data directory**.

### 3.2 SQL Query Parser

* Custom-built SQL parser or using a parser library (like ANTLR).
* Accept basic **SQL statements**:

  * `CREATE TABLE`
  * `INSERT INTO`
  * `SELECT ... FROM ... WHERE`
  * `DELETE FROM`
  * `DROP TABLE`
* Parser should convert SQL queries into an internal AST or query plan format.

### 3.3 Execution Engine

* Executes parsed queries using in-memory or file-streamed approach.
* Simple row construction from columnar files for select queries.
* Where clause evaluation should support basic conditions (`=, >, <, AND, OR`).

### 3.4 Modularity

* All major components (Parser, Storage, Executor) should be modular interfaces:

  * Pluggable storage engines
  * Pluggable index/optimizer in future
  * Clear abstraction boundaries

### 3.5 CLI Interface

* A command-line SQL shell to input and run queries.
* Support for multi-line query input and output formatting.

---

## ðŸ“Œ 4. Non-Functional Requirements

| Category         | Description                                                                      |
| ---------------- | -------------------------------------------------------------------------------- |
| ðŸ”§ Extensibility | Must be designed to allow addition of binary storage, indexing, query optimizers |
| ðŸ’¾ Portability   | Must work cross-platform (Windows/Linux/Mac)                                     |
| ðŸ§ª Testability   | Unit and integration testable modules                                            |
| ðŸ”’ Security      | No SQL injection possible in parsing phase                                       |
| ðŸ§  Simplicity    | Initial codebase should be readable, well-commented, modular                     |
| ðŸ“š Logging       | Basic logging and query audit trail should be present                            |

---

## ðŸ“Œ 5. Phase-Wise Evolution Plan

| Phase   | Description                                             |
| ------- | ------------------------------------------------------- |
| Phase 1 | Columnar text file storage, basic SQL, CLI              |
| Phase 2 | Binary storage format (block files, column compression) |
| Phase 3 | Indexing using B+ Trees or bitmap indexes               |
| Phase 4 | Query optimizer, statistics, cost-based plan            |
| Phase 5 | SQL joins, aggregations, GROUP BY, HAVING               |
| Phase 6 | Multi-threaded execution, cache, transaction log        |

---

## ðŸ“Œ 6. Module Breakdown

### 6.1 Core Modules

* `Parser` â†’ Translates SQL to AST/QueryPlan
* `StorageEngine` â†’ Interface for read/write columnar data
* `ExecutionEngine` â†’ Executes SELECT, INSERT, DELETE etc.
* `MetadataManager` â†’ Manages schema, table definitions
* `FileManager` â†’ Manages underlying file operations

### 6.2 Interfaces & Extensibility

```python
class StorageEngine(ABC):

    @abstractmethod
    def create_table(self, schema: TableSchema) -> None:
        pass

    @abstractmethod
    def insert(self, table_name: str, values: List[str]) -> None:
        pass

    @abstractmethod
    def select(self, table_name: str, columns: List[str], condition: Condition) -> ResultSet:
        pass

```

### 6.3 Data Structures

* `TableSchema`
* `QueryPlan`
* `Row/ColumnData`
* `Condition` (for WHERE clause)

---

## ðŸ“Œ 7. Deliverables (Phase 1)

* âœ… `PineDB` base implementation
* âœ… SQL CLI
* âœ… Support for simple CRUD SQL
* âœ… Columnar file-based storage
* âœ… Test cases for storage, parser, execution
* âœ… Developer documentation

---

## ðŸ“Œ 8. Example Usage

### Input:

```sql
CREATE TABLE employees (id INT, name TEXT, salary FLOAT);

INSERT INTO employees VALUES (1, 'Alice', 85000.0);
INSERT INTO employees VALUES (2, 'Bob', 72000.5);

SELECT id, name FROM employees WHERE salary > 80000;
```

### File Structure:

```
data/
 â””â”€â”€ employees/
     â”œâ”€â”€ id.txt       â†’ 1\n2\n
     â”œâ”€â”€ name.txt     â†’ Alice\nBob\n
     â””â”€â”€ salary.txt   â†’ 85000.0\n72000.5\n
```

---

## ðŸ“Œ 9. Optional Tech Stack (Flexible)

* Language: **Python**
* Parser: Custom or **ANTLR**, **JSqlParser**, **sqlglot**
* Test Framework: JUnit / PyTest
* Logging: SLF4J / Logback

---

## ðŸ“Œ 10. Future Enhancements

* Binary storage (columnar blocks with compression)
* B+ Tree indexes per column
* Cost-based query optimizer
* Distributed file support (S3, HDFS)
* SQL JOIN support
* ACID transactions with write-ahead logging

## Project Structure
```
pinedb/
â”œâ”€â”€ cli/                     # CLI interface
â”‚   â””â”€â”€ repl.py              # REPL: interactive SQL shell
â”œâ”€â”€ core/                    # Core orchestrators
â”‚   â”œâ”€â”€ engine.py            # Entry point to query execution
â”‚   â””â”€â”€ context.py           # Query execution context manager
â”œâ”€â”€ parser/                  # SQL parser components
â”‚   â”œâ”€â”€ parser.py            # SQL to AST parser
â”‚   â””â”€â”€ tokenizer.py         # (Optional) SQL tokenizer/lexer
â”œâ”€â”€ plan/                    # AST and logical query plans
â”‚   â”œâ”€â”€ ast.py               # AST node classes
â”‚   â””â”€â”€ query_plan.py        # Logical query plan representations
â”œâ”€â”€ storage/                 # Storage engine modules
â”‚   â”œâ”€â”€ base.py              # Abstract base class for storage
â”‚   â”œâ”€â”€ text_engine.py       # Text-based columnar storage engine
â”‚   â”œâ”€â”€ file_manager.py      # Low-level file I/O operations
â”‚   â””â”€â”€ metadata.py          # Table schema & catalog manager
â”œâ”€â”€ execution/               # Query execution logic
â”‚   â”œâ”€â”€ executor.py          # Query executors for SELECT, INSERT, DELETE
â”‚   â”œâ”€â”€ condition.py         # WHERE clause evaluation
â”‚   â””â”€â”€ row_builder.py       # Reconstruct rows from columnar data
â”œâ”€â”€ models/                  # Shared data models
â”‚   â”œâ”€â”€ table_schema.py      # Table and column definitions
â”‚   â”œâ”€â”€ result_set.py        # Query result wrapper
â”‚   â””â”€â”€ value.py             # Data type handling
â”œâ”€â”€ tests/                   # Unit and integration tests
â”‚   â””â”€â”€ ...
â”œâ”€â”€ logs/                    # Optional runtime logs
â”œâ”€â”€ data/                    # Actual columnar storage (per-table)
â””â”€â”€ main.py                  # Application entry point
```
Future plan:
![alt text](https://github.com/dbarshan/pine-db/blob/master/doc/roadmap.png)
